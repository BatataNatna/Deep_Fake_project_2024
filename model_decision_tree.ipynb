{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, confusion_matrix, roc_auc_score, roc_curve # this is used to evaluate the model.\n",
    "from sklearn.model_selection import train_test_split # to separate the dataset.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #used for the transformation of text data.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time #pour étudier le temps d'execution d'entrainement, de notre meilleure modèle.\n",
    "import psutil #pour calculer la mémoire.\n",
    "import os #pour calculer le temps d'execution\n",
    "import pickle as pkl #file to save and load a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>isFake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nancy Pelosi Backs BOMBSHELL Legislation That...</td>\n",
       "      <td>Donald Trump hasn t even been president for a ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ukraine prosecutor says puzzled by lack of U.S...</td>\n",
       "      <td>KIEV (Reuters) - Ukraine is puzzled by the lac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump nominates businessman with Asia backgrou...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zimbabwe's Mnangagwa opens amnesty window for ...</td>\n",
       "      <td>HARARE (Reuters) - Zimbabwe s new president, E...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OBAMA’S COMMUNIST ENVIRONMENTAL ARM Tells Kids...</td>\n",
       "      <td>Our children don t need the EPA to tell them h...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Nancy Pelosi Backs BOMBSHELL Legislation That...   \n",
       "1  Ukraine prosecutor says puzzled by lack of U.S...   \n",
       "2  Trump nominates businessman with Asia backgrou...   \n",
       "3  Zimbabwe's Mnangagwa opens amnesty window for ...   \n",
       "4  OBAMA’S COMMUNIST ENVIRONMENTAL ARM Tells Kids...   \n",
       "\n",
       "                                                text  isFake  \n",
       "0  Donald Trump hasn t even been president for a ...    True  \n",
       "1  KIEV (Reuters) - Ukraine is puzzled by the lac...   False  \n",
       "2  WASHINGTON (Reuters) - U.S. President Donald T...   False  \n",
       "3  HARARE (Reuters) - Zimbabwe s new president, E...   False  \n",
       "4  Our children don t need the EPA to tell them h...    True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('title_text.csv').drop(['Unnamed: 0'],axis=1).iloc[:,:150]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification du text en données numériques.\n",
    "Nous partons du principe que les données ont étés clean et que nous pouvons nous concerntrer à créer un model.\n",
    "\n",
    "Comme les informations principales pour définir des Fake news et des vrai news, se base sur le texte et le titre, nous devons nous focaliser sur ces informations. Il faut ainsi que nous transformons le text et le titre en données afin que notre model puisse utiliser des données numériques pour trouver la bonne réponse. Nous allons utiliser la methode de TF-IDF vectorizing.\n",
    "\n",
    "### TF-IDF vectorizer\n",
    "Cette méthode offre la possibilité de déterminer les scores TF-IDF de nos données textuelles. Ce qui signifie : \n",
    "\n",
    "TF -> la Fréquence du Terme : le nombre de fois qu'un mot apparaît, en éliminant les mots qui ne sont pas importants.\n",
    "\n",
    "IDF -> la fréquence inverse de détection : le même concept que TF, mais l'analyse va au-delà de la simple ligne, la fréquence dans l'ensemble du dataset est analysée.\n",
    "\n",
    "Ces informations seront utilisées comme données pour notre modèle d'apprentissage automatique.\n",
    "\n",
    "(il est important de faire cela uniquement sur nos données d'entraînement, sinon le modèle connaîtra les données de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['isFake'],axis=1)\n",
    "y=data['isFake']\n",
    "#spearation en données d'entrainement et de test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['text'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "\n",
    "# On fit et transforme les données d'entrainement.\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "# on transfomer uniquement le test set, sinon il va connaitre les données test...\n",
    "tfidf_test=tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model decision tree\n",
    "Un arbre de décision est une technique d'apprentissage supervisé utilisée pour résoudre des problèmes de classification et de régression. Il vise à modéliser la relation entre une variable cible, qui dans notre cas sont les Fake news, et plusieurs variables explicatives, dans ce cas nous utiliserons le texte de la news en question.\n",
    "\n",
    "L'approche de l'arbre de décision suit la stratégie de **\"diviser pour conquérir\"**.\n",
    "\n",
    "Cet algorithme itératif construit progressivement l'arbre. Au départ, il sélectionne l'attribut qui divise le mieux les données, formant des groupes en relation avec la variable cible. À chaque étape suivante, il répète ce processus pour chaque sous-ensemble créé précédemment, en se basant sur les nœuds déjà formés, jusqu'à ce que les critères de terminaison soient satisfaits (ex: le nombre maximal de niveaux dans l'arbre)\n",
    "\n",
    "Une fois l'arbre construit, il peut être utilisé pour prédire l'issue pour de nouvelles données en les faisant passer à travers l'arbre, de la racine jusqu'à une feuille, qui représente la décision finale ou la prédiction de la variable cible.\n",
    "\n",
    "src: https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.13611954237685\n"
     ]
    }
   ],
   "source": [
    "#nous construisons le modèle\n",
    "clf = DecisionTreeClassifier(max_depth=1,random_state=42)\n",
    "#nous l'entrainons\n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "#nous obtenons une accuracy du modèle\n",
    "Accuracy = clf.score(tfidf_test, y_test)\n",
    "print(Accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation\n",
    "Pour optimiser le model nous allons modifier les paramètres suivants:\n",
    "- **criterion**: Comme son nom l'indique c'est le critère de qualité que notre modèle utilise pour séparer les données et de créer les noeuds. Nous allons optimiser le modèle avec les valeurs suivantes: **[“gini”, “entropy”, “log_loss”]**\n",
    "- **max_depth**: la profondeur maximale que nous autorisons à notre arbre. Nous allons optimiser le modèle avec les valeurs suivantes: **[10,100,1000,None]**\n",
    "- **splitter**: C'est la stratégie que notre modèle utilise pour créer les noeuds. Nous allons optimiser le modèle avec les valeurs suivantes: **[“best”, “random”]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid={'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "             'max_depth':[5,10],\n",
    "             'splitter': [\"best\", \"random\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the Decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# On creer un scorer pour le grid search \n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Initialisation de la GridSearch pour trouver le meilleur C.\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params_grid, scoring=scorer, cv=5)\n",
    "\n",
    "# On lance les multiples entrainements.\n",
    "grid_search.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best combination of parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Afin d'évaluer le modèle nous faisons une représentation graphique des résultats obtenus. Nous allons étudier les metrics suivants:\n",
    "- le **temps d'entrainement** que le modèle a besoin, ainsi que son **taux de mémoire (Mo)**.\n",
    "- **matrice de confusion**, qui est un excellent choix d'évaluation de performance, car nous sommes dans le cas d'une classification binaire. \n",
    "- **L'accuracy** du model.\n",
    "- **La précision**\n",
    "- **recall**\n",
    "- **F1-score**.\n",
    "- **ROC-AUC score**\n",
    "\n",
    "src: https://www.v7labs.com/blog/performance-metrics-in-machine-learning#h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du modèle avec les meilleurs paramètres\n",
    "best_model=DecisionTreeClassifier(C=best_params['criterion'],\n",
    "                                  max_depth=best_params['max_depth'],\n",
    "                                  splitter=best_params['splitter'],\n",
    "                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voullons étudier **le temps d'entrainement (en h/m/s)** et **l'utilisation de la mémoire (Mo)** que le modèle a besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_to_hms(seconds):\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return int(hours), int(minutes), int(seconds)\n",
    "\n",
    "def bytes_to_Mo(mem_bytes):\n",
    "    mem_kb = mem_bytes / 1024  # Convertir en kilooctets\n",
    "    mem_mb = mem_kb / 1024  # Convertir en mégaoctets\n",
    "    return mem_mb\n",
    "\n",
    "#lancemenet de l'enrestristrement de la mémoire.\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before_bytes = process.memory_info().rss\n",
    "\n",
    "#lancement de l'enregistrement du temps d'entrainement.\n",
    "start_time = time.time() \n",
    "# entrainement du modèle.\n",
    "best_model.fit(tfidf_train,y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "#le temps écoulé \n",
    "elapsed_time= end_time - start_time\n",
    "\n",
    "print(f\"Temps d'entrainement (h | m | s) : {second_to_hms(elapsed_time)[0]} | {second_to_hms(elapsed_time)[1]} | {second_to_hms(elapsed_time)[2]}\")\n",
    "\n",
    "mem_after_bytes = process.memory_info().rss\n",
    "#on convertit les bytes en Mo.\n",
    "mem_bytes=mem_after_bytes - mem_before_bytes\n",
    "\n",
    "\n",
    "print(f\"Utilisation de la mémoire (Mo) : {bytes_to_Mo(mem_bytes)}\")\n",
    "#Create or open a file with write-binary mode and save the model to it\n",
    "pickle = pkl.dump(model, open('DecisionTree_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optention des prédictions de ce modèle.\n",
    "best_model = pkl.load(open('DecisionTree_model.pickle', 'rb'))\n",
    "y_pred=model.predict(tfidf_test)\n",
    "y_pred=best_model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#représentation graphique du résultat du meilleure model\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xlabel('Les labels prédits')\n",
    "plt.ylabel('Les vrais labels')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "print(f\"le modèle a donc {cm[0][0]} instances vrai Positives et {cm[1][1]} instances de Vrai négatives, {cm[1][0]} instances de Faux Positives et {cm[0][1]} instances de Faux négatives. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(y_pred,y_test)\n",
    "print(f\"Notre modèle a une précision globale de {round(acc*100,2)}%, ce qui signifie qu'il prédit correctement les classes des instances dans {round(acc*100,2)}% des cas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=precision_score(y_test,y_pred)\n",
    "print(f\"notre model a une precision de {round(precision*100,2)}% . lorsqu'il prédit une classe comme positive, il a raison dans {round(precision*100,2)}% des cas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall=recall_score(y_test,y_pred)\n",
    "print(f\"notre model arrive a détecter {round(recall*100,2)}%. Donc sur l'ensemble des vrai positives, le modèle parvient à en identifier correctement {round(recall*100,2)}% des cas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score=f1_score(y_test,y_pred)\n",
    "print(f\"notre model a un F1-score de {round(f1score*100,2)}%, ce qui signifie que il y a un excellent equilibre entre le recall et la précision.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc=roc_auc_score(y_test,y_pred)\n",
    "print(f\"Le modèle a donc une score ROC-AUC de {roc_auc} ce qui est très proche de 1, donc le modèle a une excellente capacité à différencier entres les Fake et les vrais news.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Taux de Faux Positives (%)')\n",
    "plt.ylabel('Taux de Vrai Positives (%)')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
